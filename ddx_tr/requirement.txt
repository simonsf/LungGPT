torch==2.3.0+cu121
openai==1.30.1
transformers==4.40.2
vllm==0.4.2
vllm-flash-attn==2.5.8.post1
vllm-nccl-cu12==2.18.1.0.4.0